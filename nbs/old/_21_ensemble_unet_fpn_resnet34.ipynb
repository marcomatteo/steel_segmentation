{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Inference with all the models trained.\n",
    "output-file: _21_ensemble_unet_fpn_resnet34.html\n",
    "title: Inference of ensemble models\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcomatteo/steel_segmentation/blob/master/dev_nbs/21_ensemble_unet_fpn_resnet34.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steel_segmentation.all import *\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\").type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 14 17:25:16 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 32%   48C    P0    46W / 180W |      4MiB / 16278MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:00:05.0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/fastai-UNET-ResNet34-256-stage5.pth\n",
      "../models/fastai-UNET-XResNeXt34-128x800.pth\n",
      "../models/fastai-UNET-ResNet34-smp-pytorch_dls-stage1.pth\n",
      "../models/fastai-UNET-XResNeXt34-128x800-finetuning.pth\n",
      "../models/.ipynb_checkpoints\n",
      "../models/kaggle-UNET-ResNet34.pth\n",
      "../models/kaggle-FPN-ResNet34.pth\n"
     ]
    }
   ],
   "source": [
    "print_competition_data(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset = get_test_dls(batch_size=2)\n",
    "testset = get_test_dls(root=train_path, df=train_multi, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 256, 1600])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name, x = next(iter(testset))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNET model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_segmentation_dls(4, (256, 1600), with_btfms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_trainer = unet_learner(dls=dls, arch=resnet34, metrics=seg_metrics, pretrained=True)\n",
    "unet_trainer.model_dir = models_dir\n",
    "unet_trainer = unet_trainer.load(\"fastai-UNET-ResNet34-256-stage5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = unet_trainer.model\n",
    "unet_model.to(device)\n",
    "unet_model = unet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_preds = torch.sigmoid(unet_model(x.to(device)))\n",
    "unet_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_preds[:, 1:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn_model = smp.FPN(\"resnet34\", encoder_weights='imagenet', classes=4, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict = torch.load(models_dir/\"kaggle-FPN-ResNet34.pth\")\n",
    "fpn_model.load_state_dict(loaded_dict[\"state_dict\"], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn_model.to(device)\n",
    "fpn_model = fpn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn_preds = torch.sigmoid(fpn_model(x.to(device)))\n",
    "fpn_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an ensemble we build a specific `nn.Module` class to get the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    \n",
    "    def __init__(self, models):  \n",
    "        super(Ensemble, self).__init__()\n",
    "        self.models = models\n",
    "    \n",
    "    def forward(self, x):\n",
    "        preds = [model(x.clone()) for model in self.models]\n",
    "        probs = map(f.sigmoid, preds)\n",
    "        return torch.cat(list(probs), axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [fpn_model, unet_model] # not working because unet is 5 classes and fpn 4 classes\n",
    "Ensemble()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(probability, threshold, min_size):\n",
    "    \"\"\"\n",
    "    Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored\n",
    "    \"\"\"\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((256, 1600), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 0.5\n",
    "min_size = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sizes = [3000, 3000, 3000, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3142/3142 [19:31<00:00,  2.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# start prediction on validation set\n",
    "predictions = []\n",
    "for i, batch in enumerate(tqdm(testset)):\n",
    "    fnames, images = batch\n",
    "    images = images.to(device)\n",
    "    \n",
    "    # FPN\n",
    "    fpn_preds = torch.sigmoid(fpn_model(images))\n",
    "    fpn_preds = fpn_preds.detach().cpu().numpy()\n",
    "    \n",
    "    # UNET\n",
    "    unet_preds = torch.sigmoid(unet_model(images))\n",
    "    unet_preds = unet_preds[:, 1:].detach().cpu().numpy()\n",
    "    \n",
    "    batch_preds = (fpn_preds + unet_preds) / 2\n",
    "    for fname, preds in zip(fnames, batch_preds):\n",
    "        for cls, pred in enumerate(preds):\n",
    "            min_size = min_sizes[cls]\n",
    "            pred, num = post_process(pred, best_threshold, min_size)\n",
    "            rle = mask2rle(pred)\n",
    "            name = fname + f\"_{cls+1}\"\n",
    "            predictions.append([name, rle])\n",
    "\n",
    "# save predictions to submission.csv\n",
    "df = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\n",
    "df.to_csv(sub_path/\"ensemble_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2753/2753 [08:45<00:00,  5.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# start prediction on test set\n",
    "predictions = []\n",
    "for i, batch in enumerate(tqdm(testset)):\n",
    "    fnames, images = batch\n",
    "    images = images.to(device)\n",
    "    \n",
    "    # FPN\n",
    "    fpn_preds = torch.sigmoid(fpn_model(images))\n",
    "    fpn_preds = fpn_preds.detach().cpu().numpy()\n",
    "    \n",
    "    # UNET\n",
    "    unet_preds = torch.sigmoid(unet_model(images))\n",
    "    unet_preds = unet_preds[:, 1:].detach().cpu().numpy()\n",
    "    \n",
    "    batch_preds = (fpn_preds + unet_preds) / 2\n",
    "    for fname, preds in zip(fnames, batch_preds):\n",
    "        for cls, pred in enumerate(preds):\n",
    "            min_size = min_sizes[cls]\n",
    "            pred, num = post_process(pred, best_threshold, min_size)\n",
    "            rle = mask2rle(pred)\n",
    "            name = fname + f\"_{cls+1}\"\n",
    "            predictions.append([name, rle])\n",
    "\n",
    "# save predictions to submission.csv\n",
    "df = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\n",
    "df.to_csv(sub_path/\"ensemble_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>76644 13 76895 22 77149 26 77403 30 77657 36 77694 1 77696 1 77912 43 78166 49 78216 1 78218 1 78220 1 78422 55 78677 72 78750 25 78776 1 78933 104 79188 107 79445 106 79700 109 79956 110 80212 111 80469 110 80725 112 80982 111 81238 111 81494 111 81750 113 82007 112 82263 50 82316 1 82318 57 82520 37 82580 51 82777 34 82837 52 83033 32 83095 50 83290 31 83352 51 83546 31 83609 50 83802 31 83867 54 83922 1 83938 1 83940 1 83942 1 83944 1 84059 28 84125 58 84184 1 84190 11 84315 28 84383 82 84466 1 84468 1 84470 3 84572 25 84654 82 84829 24 84914 79 85085 23 85177 72 85342 20 85435 70 85599...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId  \\\n",
       "0  0002cc93b.jpg_1   \n",
       "1  0002cc93b.jpg_2   \n",
       "2  0002cc93b.jpg_3   \n",
       "3  0002cc93b.jpg_4   \n",
       "4  00031f466.jpg_1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             EncodedPixels  \n",
       "0  76644 13 76895 22 77149 26 77403 30 77657 36 77694 1 77696 1 77912 43 78166 49 78216 1 78218 1 78220 1 78422 55 78677 72 78750 25 78776 1 78933 104 79188 107 79445 106 79700 109 79956 110 80212 111 80469 110 80725 112 80982 111 81238 111 81494 111 81750 113 82007 112 82263 50 82316 1 82318 57 82520 37 82580 51 82777 34 82837 52 83033 32 83095 50 83290 31 83352 51 83546 31 83609 50 83802 31 83867 54 83922 1 83938 1 83940 1 83942 1 83944 1 84059 28 84125 58 84184 1 84190 11 84315 28 84383 82 84466 1 84468 1 84470 3 84572 25 84654 82 84829 24 84914 79 85085 23 85177 72 85342 20 85435 70 85599...  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
