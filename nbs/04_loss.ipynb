{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Various loss functions in PyTorch\n",
    "output-file: loss.html\n",
    "title: Loss functions\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp losses\n",
    "# all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastai.torch_core import TensorBase\n",
    "from fastai.losses import *\n",
    "from fastai.callback.core import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import numpy as np\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import segmentation_models_pytorch as smp\n",
    "from steel_segmentation.utils import get_train_df\n",
    "from steel_segmentation.transforms import SteelDataBlock, SteelDataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beanTech\\miniconda3\\envs\\steel_segmentation\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 1568]) cuda:0\n",
      "torch.Size([8, 4, 224, 1568]) cpu\n"
     ]
    }
   ],
   "source": [
    "path = Path(\"../data\")\n",
    "train_pivot = get_train_df(path=path, pivot=True)\n",
    "block = SteelDataBlock(path)\n",
    "dls = SteelDataLoaders(block, train_pivot, bs=8)\n",
    "xb, yb = dls.one_batch()\n",
    "print(xb.shape, xb.device)\n",
    "print(yb.shape, yb.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beanTech\\miniconda3\\envs\\steel_segmentation\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "model = smp.Unet(\"resnet18\", classes=4).to(device)\n",
    "\n",
    "logits = model(xb)\n",
    "probs = torch.sigmoid(logits)\n",
    "preds = ( probs > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#reference: https://github.com/asanakoy/kaggle_carvana_segmentation/blob/master/asanakoy/losses.py\n",
    "class SoftDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num = labels.size(0)\n",
    "        m1 = probs.view(num, -1)\n",
    "        m2 = labels.view(num, -1)\n",
    "        intersection = (m1 * m2)\n",
    "        score = 2. * (intersection.sum(1) + 1) / (m1.sum(1) + m2.sum(1) + 1)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage(0.9883)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = SoftDiceLoss()\n",
    "criterion(logits.detach().cpu(), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#reference: https://github.com/zdaiot/Kaggle-Steel-Defect-Detection\n",
    "class WeightedSoftDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, size_average=True, weight=[0.2, 0.8]):\n",
    "        super().__init__()\n",
    "        self.size_average = size_average\n",
    "        self.weight = torch.FloatTensor(weight)\n",
    "\n",
    "    def forward(self, logit_pixel, truth_pixel):\n",
    "        batch_size = len(logit_pixel)\n",
    "        logit = logit_pixel.view(batch_size, -1)\n",
    "        truth = truth_pixel.view(batch_size, -1)\n",
    "        assert(logit.shape == truth.shape)\n",
    "\n",
    "        loss = self.soft_dice_criterion(logit, truth)\n",
    "\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "    def soft_dice_criterion(self, logit, truth):\n",
    "        batch_size = len(logit)\n",
    "        probability = torch.sigmoid(logit)\n",
    "\n",
    "        p = probability.view(batch_size, -1)\n",
    "        t = truth.view(batch_size, -1)\n",
    "\n",
    "        w = truth.detach()\n",
    "        self.weight = self.weight.type_as(logit)\n",
    "        w = w * (self.weight[1] - self.weight[0]) + self.weight[0]\n",
    "\n",
    "        p = w * (p*2 - 1)  #convert to [0,1] --> [-1, 1]\n",
    "        t = w * (t*2 - 1)\n",
    "\n",
    "        intersection = (p * t).sum(-1)\n",
    "        union =  (p * p).sum(-1) + (t * t).sum(-1)\n",
    "        dice  = 1 - 2 * intersection/union\n",
    "\n",
    "        loss = dice\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMask(0.9471)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = WeightedSoftDiceLoss()\n",
    "criterion(logits.detach().cpu(), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#reference: https://github.com/zdaiot/Kaggle-Steel-Defect-Detection\n",
    "class SoftBCEDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, bce_pos_weight, size_average=True, dice_weights=[0.2, 0.8], loss_weights=[0.7, 0.3]):\n",
    "        super().__init__()\n",
    "        self.size_average = 'mean' if size_average else 'none'\n",
    "        self.loss_weights = loss_weights\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(\n",
    "            reduction=self.size_average, \n",
    "            pos_weight=torch.tensor(bce_pos_weight)\n",
    "        )\n",
    "        self.softdiceloss = WeightedSoftDiceLoss(\n",
    "            size_average=self.size_average, \n",
    "            weight=dice_weights\n",
    "        )\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input, target = TensorBase(input).float(), TensorBase(target).float()\n",
    "        bce_loss = self.bce_loss(input, target)\n",
    "        soft_dice_loss = self.softdiceloss(input, target)\n",
    "        loss = self.loss_weights[0] * bce_loss + self.loss_weights[1] * soft_dice_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.7872)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = SoftBCEDiceLoss(bce_pos_weight=1.5)\n",
    "criterion(logits.detach().cpu(), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#reference: https://github.com/zdaiot/Kaggle-Steel-Defect-Detection\n",
    "class MultiClassesSoftBCEDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, classes_num=4, size_average=True, dice_weights=[0.2, 0.8], bce_pos_weights=[2.0,2.0,1.0,1.5], loss_weights=[0.7, 0.3], thresh=0.5):\n",
    "        super().__init__()\n",
    "        self.thresh = thresh\n",
    "        self.classes_num = classes_num\n",
    "        self.soft_bce_dice_losses = [\n",
    "            SoftBCEDiceLoss(bce_pos_weight=pos_weight, size_average=size_average, dice_weights=dice_weights, loss_weights=loss_weights)\n",
    "            for pos_weight in bce_pos_weights\n",
    "        ]\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input: tensor, [batch_size, classes_num, height, width]\n",
    "            target: tensor, [batch_size, classes_num, height, width]\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        for class_index in range(self.classes_num):\n",
    "            input_single_class = input[:, class_index, :, :]\n",
    "            target_singlt_class = target[:, class_index, :, :]\n",
    "            single_class_loss = self.soft_bce_dice_losses[class_index](input_single_class, target_singlt_class)\n",
    "            loss += single_class_loss\n",
    "\n",
    "        loss /= self.classes_num\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def decodes(self, x):    \n",
    "        return (x>self.thresh).float().argmax(dim=1)\n",
    "\n",
    "    def activation(self, x): \n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.7833)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = MultiClassesSoftBCEDiceLoss()\n",
    "loss = criterion(logits.detach().cpu(), yb)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 224, 1568])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion.decodes(logits.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 224, 1568])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion.activation(logits.detach().cpu()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Tensorboard callback we need this Learner Callback to handle the step after the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LossEnabler(Callback):\n",
    "    \"\"\"Cast predictions and labels to TensorBase to compute the smp.losses\"\"\"\n",
    "    def after_pred(self):\n",
    "        if len(self.learn.yb) > 0:\n",
    "            yb = self.learn.yb[0]\n",
    "            self.learn.yb = (TensorBase(yb), )\n",
    "            self.learn.pred = TensorBase(self.learn.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.valid.bs "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28655ac308a3066e78dcd35793da650bd1be67b358d93812a1ea5ca876afb9ba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('steel_segmentation': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
