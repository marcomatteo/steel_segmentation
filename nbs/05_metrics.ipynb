{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: A collection of Metrics used in the segmentation models\n",
    "output-file: metrics.html\n",
    "title: Metrics\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp metrics\n",
    "# all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import numpy as np\n",
    "from fastai.torch_core import TensorBase, flatten_check\n",
    "from fastai.metrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import numpy as np\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import segmentation_models_pytorch as smp\n",
    "from steel_segmentation.utils import get_train_df\n",
    "from steel_segmentation.transforms import SteelDataBlock, SteelDataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beanTech\\miniconda3\\envs\\steel_segmentation\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 1568]) cuda:0\n",
      "torch.Size([8, 4, 224, 1568]) cpu\n"
     ]
    }
   ],
   "source": [
    "path = Path(\"../data\")\n",
    "train_pivot = get_train_df(path=path, pivot=True)\n",
    "block = SteelDataBlock(path)\n",
    "dls = SteelDataLoaders(block, train_pivot, bs=8)\n",
    "xb, yb = dls.one_batch()\n",
    "print(xb.shape, xb.device)\n",
    "print(yb.shape, yb.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\"resnet18\", classes=4).to(device)\n",
    "\n",
    "logits = model(xb)\n",
    "probs = torch.sigmoid(logits)\n",
    "preds = ( probs > 0.5).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dice metric\n",
    "The competition [evaluation metric](https://www.kaggle.com/c/severstal-steel-defect-detection/overview/evaluation) is defined as:\n",
    "\n",
    "> This competition is evaluated on the mean Dice coefficient. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:\n",
    "\n",
    "$$\n",
    "J(A,B) = \\frac{2 * |A \\cap B|}{|A| \\cup |B|}\n",
    "$$\n",
    "\n",
    "> where X is the predicted set of pixels and Y is the ground truth. The Dice coefficient is defined to be 1 when both X and Y are empty. The leaderboard score is the mean of the Dice coefficients for each <ImageId, ClassId> pair in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section there are all the metric that can be used to evaluate the performances of the segmentation models trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated training with `compute_val` and a test Learner with `TstLearner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For testing: a fake learner and a metric that isn't an average\n",
    "@delegates()\n",
    "class TstLearner(Learner):\n",
    "    def __init__(self,dls=None,model=None,**kwargs): \n",
    "        self.pred,self.xb,self.yb = None,None,None\n",
    "        self.loss_func=BCEWithLogitsLossFlat()\n",
    "        \n",
    "#Go through a fake cycle with various batch sizes and computes the value of met\n",
    "def compute_val(met, pred, y):\n",
    "    met.reset()\n",
    "    vals = [0,6,15,20]\n",
    "    learn = TstLearner()\n",
    "    for i in range(3):\n",
    "        learn.pred = pred[vals[i]:vals[i+1]]\n",
    "        learn.yb = ( y[vals[i]:vals[i+1]], )\n",
    "        met.accumulate(learn)\n",
    "    return met.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fastai` library comes with a dice metric for multiple channel masks. As a segmentation metric in this frameworks, it expects a flatten mask for targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "multidice_obj = DiceMulti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1798790120410166"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_val(multidice_obj, pred=preds.detach().cpu(), y=yb.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we slightly change the `DiceMulti` for a 4-channel mask as targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ModDiceMulti(Metric):\n",
    "    \"Averaged Dice metric (Macro F1) for multiclass target in segmentation\"\n",
    "\n",
    "    def __init__(self, axis=1, with_logits=False):\n",
    "        self.axis = axis\n",
    "        self.with_logits = with_logits\n",
    "\n",
    "    def reset(self): self.inter, self.union =  {}, {}\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        if self.with_logits:\n",
    "            logit = learn.pred\n",
    "            prob = torch.sigmoid(logit)\n",
    "            pred = (prob > 0.5).float().argmax(dim=self.axis)\n",
    "        else:\n",
    "            pred = learn.pred.argmax(dim=self.axis)\n",
    "\n",
    "        y = learn.yb[0]\n",
    "        # Added to deal with 4-channels masks\n",
    "        if pred.shape != y.shape:\n",
    "            y = y.argmax(dim=self.axis)\n",
    "\n",
    "        pred, targ = flatten_check(pred, y)\n",
    "        for c in range(learn.pred.shape[self.axis]):\n",
    "            p = torch.where(pred == c, 1, 0)\n",
    "            t = torch.where(targ == c, 1, 0)\n",
    "            p, t = TensorBase(p), TensorBase(t) # may be redundant (old fastai bug)\n",
    "            c_inter = (p*t).float().sum().item()\n",
    "            c_union = (p+t).float().sum().item()\n",
    "            if c in self.inter:\n",
    "                self.inter[c] += c_inter\n",
    "                self.union[c] += c_union\n",
    "            else:\n",
    "                self.inter[c] = c_inter\n",
    "                self.union[c] = c_union\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        binary_dice_scores = np.array([])\n",
    "        for c in self.inter:\n",
    "            binary_dice_scores = np.append(\n",
    "                binary_dice_scores,\n",
    "                2.*self.inter[c]/self.union[c] if self.union[c] > 0 else np.nan)\n",
    "        self.binary_dice_scores = binary_dice_scores\n",
    "        return np.nanmean(binary_dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2130325182791189"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_obj = ModDiceMulti(with_logits=True)\n",
    "compute_val(dice_obj, pred=logits.detach().cpu(), y=yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2130325182791189"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_obj = ModDiceMulti()\n",
    "compute_val(dice_obj, pred=preds.detach().cpu(), y=yb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28655ac308a3066e78dcd35793da650bd1be67b358d93812a1ea5ca876afb9ba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('steel_segmentation': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
