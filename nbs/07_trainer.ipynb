{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# skip\n",
    "!git clone https://github.com/marcomatteo/steel_segmentation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# skip\n",
    "!pip install -e steel_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "\n",
    "> Train classes for Deep Learning models with Fastai/Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from steel_segmentation.metadata import *\n",
    "from steel_segmentation.masks import *\n",
    "from steel_segmentation.datasets import *\n",
    "from steel_segmentation.dataloaders import *\n",
    "from steel_segmentation.metrics import *\n",
    "from steel_segmentation.loss import *\n",
    "\n",
    "from fastcore.foundation import *\n",
    "from fastai.vision.all import *\n",
    "import fastai\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "only_imgs = [\"0a1cade03.jpg\", \"bca4ae758.jpg\", \"988cf521f.jpg\", \"b6a257b28.jpg\",\n",
    "             \"b2ad335bf.jpg\", \"72aaba8ad.jpg\", \"f383950e8.jpg\"]\n",
    "train = train[train[\"ImageId\"].isin(only_imgs)].copy()\n",
    "train_all = train_all[train_all[\"ImageId\"].isin(only_imgs)].copy()\n",
    "train_multi = train_multi[train_multi[\"ImageId\"].isin(only_imgs)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "models_dir = path.parent / \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Paperspace Gradient machine I stored these models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/fastai-UNET-ResNet34-256-stage5.pth\n",
      "../models/.ipynb_checkpoints\n",
      "../models/kaggle-UNET-ResNet34.pth\n",
      "../models/fastai-UNET-ResNet34-256-stage3.pth\n",
      "../models/kaggle-FPN-ResNet34.pth\n"
     ]
    }
   ],
   "source": [
    "# missing\n",
    "print_competition_data(models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast.ai Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "class_metrics = [accuracy_multi, PrecisionMulti(), RecallMulti()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example to train fast.ai models with a classification `Learner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing\n",
    "bs = 4\n",
    "\n",
    "dls = get_classification_dls(bs)\n",
    "arch = partial(resnet18, pretrained=True)\n",
    "class_learner = cnn_learner(\n",
    "    dls=dls, arch=arch, metrics=class_metrics, pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast.ai Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a classification model to get an encoder that know how to classify defects pixels.\n",
    "Then, we build a UNet from the trained encoder and train a segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "seg_metrics = [DiceMulti(), KaggleDice()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example to train fast.ai models with a segmentation `Learner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing\n",
    "bs = 4\n",
    "szs = (128, 800)\n",
    "\n",
    "#dls = get_segmentation_dls_from_df(train_multi, bs, szs)\n",
    "dls = get_segmentation_dls(bs, szs)\n",
    "segmentation_learner = unet_learner(\n",
    "    dls=dls, arch=resnet18, metrics=seg_metrics, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/steel_segmentation/steel_segmentation/metrics.py:53: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(binary_dice_scores)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DynamicUnet (Input shape: 4)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     4 x 64 x 64 x 400   \n",
       "Conv2d                                    9408       False     \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      False     \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     4 x 128 x 16 x 100  \n",
       "Conv2d                                    73728      False     \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    8192       False     \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     False     \n",
       "BatchNorm2d                               256        True      \n",
       "____________________________________________________________________________\n",
       "                     4 x 256 x 8 x 50    \n",
       "Conv2d                                    294912     False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    32768      False     \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     False     \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 4 x 25    \n",
       "Conv2d                                    1179648    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    131072     False     \n",
       "BatchNorm2d                               1024       True      \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    False     \n",
       "BatchNorm2d                               1024       True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     4 x 1024 x 4 x 25   \n",
       "Conv2d                                    4719616    True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 4 x 25    \n",
       "Conv2d                                    4719104    True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     4 x 1024 x 4 x 25   \n",
       "Conv2d                                    525312     True      \n",
       "ReLU                                                           \n",
       "PixelShuffle                                                   \n",
       "BatchNorm2d                               512        True      \n",
       "Conv2d                                    2359808    True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359808    True      \n",
       "ReLU                                                           \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     4 x 1024 x 8 x 50   \n",
       "Conv2d                                    525312     True      \n",
       "ReLU                                                           \n",
       "PixelShuffle                                                   \n",
       "BatchNorm2d                               256        True      \n",
       "Conv2d                                    1327488    True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    1327488    True      \n",
       "ReLU                                                           \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     4 x 768 x 16 x 100  \n",
       "Conv2d                                    295680     True      \n",
       "ReLU                                                           \n",
       "PixelShuffle                                                   \n",
       "BatchNorm2d                               128        True      \n",
       "Conv2d                                    590080     True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    590080     True      \n",
       "ReLU                                                           \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 32 x 200  \n",
       "Conv2d                                    131584     True      \n",
       "ReLU                                                           \n",
       "PixelShuffle                                                   \n",
       "BatchNorm2d                               128        True      \n",
       "____________________________________________________________________________\n",
       "                     4 x 96 x 64 x 400   \n",
       "Conv2d                                    165984     True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    83040      True      \n",
       "ReLU                                                           \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     4 x 384 x 64 x 400  \n",
       "Conv2d                                    37248      True      \n",
       "ReLU                                                           \n",
       "PixelShuffle                                                   \n",
       "ResizeToOrig                                                   \n",
       "MergeLayer                                                     \n",
       "Conv2d                                    88308      True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    88308      True      \n",
       "Sequential                                                     \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     4 x 5 x 128 x 800   \n",
       "Conv2d                                    500        True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 31,113,308\n",
       "Total trainable params: 19,946,396\n",
       "Total non-trainable params: 11,166,912\n",
       "\n",
       "Optimizer used: <function Adam at 0x7f651f0eb9d0>\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing\n",
    "segmentation_learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load custom weights in the Unet Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing\n",
    "encoder_path = models_dir / \"ResNet18-2_class.pt\"\n",
    "segmentation_learner.model[0].load_state_dict(\n",
    "    torch.load(encoder_path), strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this project is not only FastAi. I based an alternative solution based on this [kernel](https://www.kaggle.com/rishabhiitbhu/unet-starter-kernel-pytorch-lb-0-88). \n",
    "In this notebook I will go through each part of the model from that kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda\n",
    "model = smp.Unet(\"resnet18\", \n",
    "                 encoder_weights=\"imagenet\", \n",
    "                 classes=4, \n",
    "                 activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Trainer:\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    \n",
    "    def __init__(self, model, save_path,\n",
    "                 num_epochs=20, lr=5e-4, \n",
    "                 bs=16, num_workers=6):\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = {\"train\": bs, \"val\": bs//2}\n",
    "        self.accumulation_steps = 32 // self.batch_size['train']\n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.net = model\n",
    "        self.save_path = save_path\n",
    "        \n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        \n",
    "        self.dataloaders = {\n",
    "            phase: get_train_dls(\n",
    "                phase=phase,\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        \n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.iou_scores = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        \n",
    "    def forward(self, images, targets):\n",
    "        \"\"\"\n",
    "        Forward pass: \n",
    "            load to GPU the imgs and masks,\n",
    "            calculate predictions,\n",
    "            calculate loss\n",
    "        \n",
    "        Returns:\n",
    "            loss and predictions\n",
    "        \"\"\"\n",
    "        images = images.to(self.device)\n",
    "        masks = targets.to(self.device)\n",
    "        preds = self.net(images)\n",
    "        loss = self.loss_fn(preds, masks)\n",
    "        return loss, preds\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        \"\"\"\n",
    "        Iterate throught each batch in training or validation phase.\n",
    "        \"\"\"\n",
    "        meter = Meter(phase, epoch)\n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: {epoch} | phase: {phase} | ‚è∞: {start}\")\n",
    "        \n",
    "        batch_size = self.batch_size[phase]\n",
    "        self.net.train(phase == \"train\")\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "#         tk0 = tqdm(dataloader, total=total_batches)\n",
    "        self.optimizer.zero_grad()\n",
    "        for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n",
    "            images, targets = batch\n",
    "            loss, outputs = self.forward(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            outputs = outputs.detach().cpu()\n",
    "            meter.update(targets, outputs)\n",
    "#             tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n",
    "\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n",
    "        \n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(dice)\n",
    "        self.iou_scores[phase].append(iou)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Training loop for each epochs.\n",
    "        \"\"\"\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "            }\n",
    "            with torch.no_grad():\n",
    "                val_loss = self.iterate(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "            if val_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = val_loss\n",
    "                torch.save(state, self.save_path)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Trainer.__init__\" class=\"doc_header\"><code>Trainer.__init__</code><a href=\"__main__.py#L5\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Trainer.__init__</code>(**`model`**, **`save_path`**, **`num_epochs`**=*`20`*, **`lr`**=*`0.0005`*, **`bs`**=*`16`*, **`num_workers`**=*`6`*)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Trainer.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Trainer.forward\" class=\"doc_header\"><code>Trainer.forward</code><a href=\"__main__.py#L42\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Trainer.forward</code>(**`images`**, **`targets`**)\n",
       "\n",
       "Forward pass: \n",
       "    load to GPU the imgs and masks,\n",
       "    calculate predictions,\n",
       "    calculate loss\n",
       "\n",
       "Returns:\n",
       "    loss and predictions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Trainer.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Trainer.iterate\" class=\"doc_header\"><code>Trainer.iterate</code><a href=\"__main__.py#L58\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Trainer.iterate</code>(**`epoch`**, **`phase`**)\n",
       "\n",
       "Iterate throught each batch in training or validation phase."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Trainer.iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Trainer.start\" class=\"doc_header\"><code>Trainer.start</code><a href=\"__main__.py#L98\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Trainer.start</code>()\n",
       "\n",
       "Training loop for each epochs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Trainer.start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda\n",
    "model_trainer = Trainer(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_core.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_models.dataloaders.ipynb.\n",
      "Converted 04_models.metrics.ipynb.\n",
      "Converted 06_models.model.ipynb.\n",
      "Converted 07_models.predict.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
