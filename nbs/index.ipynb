{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: A walk through different solutions for the Severstal Kaggle competition.\n",
    "output-file: index.html\n",
    "title: Kaggle Severstal Steel Defect Detection\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| missing\n",
    "#!git clone https://github.com/marcomatteo/steel_segmentation.git\n",
    "#!pip install -e steel_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CI](https://github.com/marcomatteo/steel_segmentation/workflows/CI/badge.svg?branch=master) \r\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/marcomatteo/steel_deployment/HEAD?urlpath=%2Fvoila%2Frender%2Fsteel_deploy.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository wants to explore different solutions for the [Severstal](https://www.kaggle.com/c/severstal-steel-defect-detection/overview) competition hosted by Kaggle.\r\n",
    "Kaggle is a platform that provides various datasets from the real world machine learning problems and engages a large community of people.\r\n",
    "Severstal is a Russian company operating in the steel and mining industry. It creates a vast industrial data lake and in the 2019 looked to machine learning to improve automation, increase efficiency, and maintain high quality in their production.\r\n",
    "\r\n",
    "The goal is to detect steel defects with segmentation models. The solutions are based on [Pytorch](https://pytorch.org/get-started/locally/) with [FastAI](https://docs.fast.ai/#Installing) as high level deep learning framework.\r\n",
    "\r\n",
    "In this repository you will find some Jupyter Notebooks used to build the `steel_segmentation` library with [nbdev](https://nbdev.fast.ai/) and the training notebooks.\r\n",
    "\r\n",
    "In the [steel_deployment](https://github.com/marcomatteo/steel_deployment) repository you can find a Binder/Voila web app for the deployment of the models built with this library (still updating)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install this package, clone and install the repository and install via:\r\n",
    "\r\n",
    "```\r\n",
    "pip install git+https://github.com/marcomatteo/steel_segmentation.git\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editable install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install and edit this package:\r\n",
    "\r\n",
    "```\r\n",
    "clone git+https://github.com/marcomatteo/steel_segmentation.git\r\n",
    "pip install -e steel_segmentation\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "The library is based on `nbdev`, a powerful tool that builds a python package from Juptyer Notebooks.\r\n",
    "\r\n",
    "```\r\n",
    "pip install nbdev\r\n",
    "```\r\n",
    "\r\n",
    "To create the library, the documentation and tests use these commands:\r\n",
    "```\r\n",
    "nbdev_clean_nbs\r\n",
    "nbdev_build_lib\r\n",
    "nbdev_test_nbs\r\n",
    "nbdev_build_docs\r\n",
    "```\r\n",
    "\r\n",
    "This enviroment works on MacOS and Linux. In Windows the WLS with Ubuntu 20.04 is raccomended.\r\n",
    "\r\n",
    "Training only in Windows needs one package more to solve `ipykernel` issues: \r\n",
    "```\r\n",
    "conda install pywin32\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the [Kaggle](https://www.kaggle.com/) competition data you will need an account (if this is the first time with the API follow this [link](https://github.com/Kaggle/kaggle-api)) to generate the credentials, download and copy the `kaggle.json` into the repository directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp ../kaggle.json ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're authenticated with the Kaggle API (you'll need `kaggle` so `pip install kaggle` first), download and unzip the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c severstal-steel-defect-detection -p {path}\n",
    "!mkdir data\n",
    "!unzip -q -n {path}/severstal-steel-defect-detection.zip -d {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the experiments are based on Jupyter Notebooks and in the `nbs` folder there are all the notebooks used to build the `steel_segmentation` library (still updating):\r\n",
    "\r\n",
    "- [Explorating Data Analysis](https://marcomatteo.github.io/steel_segmentation/eda.html): data analysis, plots and utility functions.\r\n",
    "- [Transforms](https://marcomatteo.github.io/steel_segmentation/transforms.html): leveraging Middle-level API of `fastai` for custom data loading pipeline.\r\n",
    "- [Optimizer utility functions](https://marcomatteo.github.io/steel_segmentation/optimizer.html)\r\n",
    "- [Loss functions](https://marcomatteo.github.io/steel_segmentation/loss.html)\r\n",
    "- [Metrics](https://marcomatteo.github.io/steel_segmentation/metrics.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training script in `scripts` folder:\r\n",
    "\r\n",
    "- `segmentation_train.py`: training segmentation models from [qubvel repository](https://github.com/qubvel/segmentation_models.pytorch).\r\n",
    "- `create_submission.py` : create a kaggle submission from a segmentation model trained and save the csv in `data/submissions/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Models|Public score|Private score|Percentile Private LB|\n",
    "|------|------------|-------------|----------|\n",
    "|Pytorch UNET-ResNet18|0.87530|0.85364|85°|\n",
    "|Pytorch UNET-ResNet34|0.88591|0.88572|46°|\n",
    "|FastAI UNET-ResNet34|0.88648|0.88830|23°|\n",
    "|Pytorch FPN-ResNet34|0.89054|0.88911|19°|\n",
    "|Ensemble UNET-ResNet34_FPN-ResNet34|0.89184|0.89262|16°|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
